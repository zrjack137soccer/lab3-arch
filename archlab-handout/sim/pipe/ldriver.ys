#######################################################################
# Test for copying block of size 63;
#######################################################################
	.pos 0
main:	irmovq Stack, %rsp  	# Set up stack pointer

	# Set up arguments for copy function and then invoke it
	irmovq $63, %rdx		# src and dst have 63 elements
	irmovq dest, %rsi	# dst array
	irmovq src, %rdi	# src array
	call ncopy		 
	halt			# should halt with num nonzeros in %rax
StartFun:
#/* $begin ncopy-ys */
##################################################################
# ncopy.ys - Copy a src block of len words to dst.
# Return the number of positive words (>0) contained in src.
#
# Zachry Jacklin Section 2 NetId: jacklinz
#
# In my code I modified it in the following steps:
# 1. I added iaddq to shorten steps
# 2. I made sure to store each point of src in a seperate register from %r8 to %rbx
# 3. I added more loops to do the process of unrolling
# 4. I initialized all the registers in loop to avoid any bad copying.
#
#
##################################################################
# Do not modify this portion
# Function prologue.
# %rdi = src, %rsi = dst, %rdx = len
ncopy:

##################################################################
# You can modify this portion
	# Loop header

	xorq %rax, %rax		# set count to 0
	rrmovq %rdx, %rcx	# copy len to %rcx
	iaddq $-8, %rcx		# %rcx - 8
	jle Next		# jump to next

Loop:	
	mrmovq (%rdi), %r8	# src[i] to %r8
	mrmovq 8(%rdi), %r9	# src[i+1] to %r9
	mrmovq 16(%rdi), %r10	# src[i+2] to %r10
	mrmovq 24(%rdi), %r11	# src[i+3] to %r11
	mrmovq 32(%rdi), %r12	# src[i+4] to %r12
	mrmovq 40(%rdi), %r13	# src[i+5] to %r13
	mrmovq 48(%rdi), %r14	# src[i+6] to %r14
	mrmovq 56(%rdi), %rbx	# src[i+7] to %rbx
	rmmovq %r8, (%rsi)	# src[i] to dst[i]
	rmmovq %r9, 8(%rsi)	# src[i+1] to dst[i+1]
	rmmovq %r10, 16(%rsi)	# src[i+2] to dst[i+2]
	rmmovq %r11, 24(%rsi)	# src[i+3] to dst[i+3] 
	rmmovq %r12, 32(%rsi)	# src[i+4] to dst[i+4]
	rmmovq %r13, 40(%rsi)	# src[i+5] to dst[i+5]
	rmmovq %r14, 48(%rsi)	# src[i+6] to dst[i+6]
	rmmovq %rbx, 56(%rsi)	# src[i+7] to dst[i+7]
	
ele1:
	andq %r8, %r8		# %r8 < 0?
	jle ele2		# jump to element2 if less than 
	iaddq $1, %rax		# count++

ele2:
	andq %r9, %r9		# %r9 < 0?
	jle ele3		# jump to element3 if less than
	iaddq $1, %rax		# count++

ele3:
	andq %r10, %r10		# %r10 < 0?
	jle ele4		# jump to element4 if less than
	iaddq $1, %rax		# count++

ele4:
	andq %r11, %r11		# %r11 < 0?
	jle ele5		# jump to element5 if less than
	iaddq $1, %rax		# count++

ele5:
	andq %r12, %r12		# %r12 < 0?
	jle ele6		# jump to element6 if less than
	iaddq $1, %rax		# count++

ele6:
	andq %r13, %r13		# %r13 < 0?
	jle ele7		# jump to element7 if less than
	iaddq $1, %rax		# count++

ele7:
	andq %r14, %r14		# %r14 < 0?
	jle ele8		# jump to element8 if less than
	iaddq $1, %rax		# count++

ele8:
	andq %rbx, %rbx		# %rbx < 0?
	jle Npos1		# jump to Npos1 if less than
	iaddq $1, %rax		# count++

Npos1:
	iaddq $64, %rdi		# src++
	iaddq $64, %rsi		# dst++
	iaddq $-8, %rdx		# len--
	iaddq $-8, %rcx		# (len - 8)--
	jg Loop

Next:
	andq %rdx, %rdx		# %rdx < 0?
	jle Done		# jump to done if less than

Loop2:
	mrmovq (%rdi), %rbx	# src[i]++ to %rbx
	rmmovq %rbx, (%rsi)	# src[i]++ to dst[i]++
	andq %rbx, %rbx		# %rbx < 0?
	jle Npos2		# jump to Npos2 if less than
	iaddq $1, %rax		# count++

Npos2:
	iaddq $8, %rdi		# (src + 8)++
	iaddq $8, %rsi		# (dst + 8)++
	iaddq $-1, %rdx		# len--
	jg Loop2
	

##################################################################
# Do not modify the following section of code
# Function epilogue.
Done:
	ret
##################################################################
# Keep the following label at the end of your function
End:
#/* $end ncopy-ys */
EndFun:

###############################
# Source and destination blocks 
###############################
	.align 8
src:
	.quad -1
	.quad -2
	.quad -3
	.quad 4
	.quad -5
	.quad -6
	.quad -7
	.quad 8
	.quad 9
	.quad -10
	.quad -11
	.quad 12
	.quad -13
	.quad -14
	.quad -15
	.quad -16
	.quad -17
	.quad 18
	.quad -19
	.quad 20
	.quad -21
	.quad -22
	.quad 23
	.quad -24
	.quad 25
	.quad -26
	.quad -27
	.quad 28
	.quad 29
	.quad 30
	.quad -31
	.quad 32
	.quad 33
	.quad 34
	.quad 35
	.quad 36
	.quad -37
	.quad -38
	.quad -39
	.quad -40
	.quad 41
	.quad -42
	.quad 43
	.quad 44
	.quad -45
	.quad -46
	.quad -47
	.quad -48
	.quad -49
	.quad 50
	.quad 51
	.quad 52
	.quad 53
	.quad -54
	.quad -55
	.quad 56
	.quad 57
	.quad 58
	.quad 59
	.quad 60
	.quad 61
	.quad 62
	.quad 63
	.quad 0xbcdefa # This shouldn't get moved

	.align 16
Predest:
	.quad 0xbcdefa
dest:
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
Postdest:
	.quad 0xdefabc

.align 8
# Run time stack
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0

Stack:
